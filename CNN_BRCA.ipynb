{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajohn256/Deep-Learning-With-Pytorch/blob/main/CNN_BRCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8FV2qPqHFDnz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "8g1MvrQiMzbm"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bpk1QLubFDn2"
      },
      "outputs": [],
      "source": [
        "# Define data transformations for data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        # transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1XY6dIYmFDn5"
      },
      "outputs": [],
      "source": [
        "# Define the data directory\n",
        "data_dir = './BRCA_DATASET'\n",
        "\n",
        "# # Create data loaders\n",
        "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove .ipynb_checkpoints directory if it exists\n",
        "for split in ['train', 'test']:\n",
        "    checkpoint_dir = os.path.join(data_dir, split, '.ipynb_checkpoints')\n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        shutil.rmtree(checkpoint_dir)  # Remove the directory\n",
        "\n",
        "# Create data loaders\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}"
      ],
      "metadata": {
        "id": "xSrIgHXIHClZ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVTbSCaAFDn7",
        "outputId": "5422d817-1deb-4eaf-f992-14b578661ce7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': Dataset ImageFolder\n",
              "     Number of datapoints: 16\n",
              "     Root location: ./BRCA_DATASET/train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
              "                RandomHorizontalFlip(p=0.5)\n",
              "                ToTensor()\n",
              "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "            ),\n",
              " 'test': Dataset ImageFolder\n",
              "     Number of datapoints: 16\n",
              "     Root location: ./BRCA_DATASET/test\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=256, interpolation=bilinear, max_size=None, antialias=True)\n",
              "                CenterCrop(size=(224, 224))\n",
              "                ToTensor()\n",
              "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "            )}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "image_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTiMyyObFDn-",
        "outputId": "b6a1fc6e-b19a-462f-cb00-760f0163b4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': 16, 'test': 16}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['benign', 'malignant']"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "#image_datasets\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "print(dataset_sizes)\n",
        "\n",
        "class_names = image_datasets['train'].classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "VQlBcFYNFDoA"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(image_datasets['train'], batch_size=30, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(image_datasets['test'], batch_size=30, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivaIWnJ_FDoA",
        "outputId": "90eac5c2-43ec-47e7-cd57-87808e9d6af3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "image,label = image_datasets['train'][0]\n",
        "image.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "OUjRVKU0FDoB"
      },
      "outputs": [],
      "source": [
        "# conv1 = nn.Conv2d(3,6,3,1)\n",
        "# conv2 = nn.Conv2d(6,16,3,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "ykLuTzaKFDoC"
      },
      "outputs": [],
      "source": [
        "# for i, (X_Train,y_train) in enumerate(image_datasets['train']):\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "6W8eEx9pFDoD"
      },
      "outputs": [],
      "source": [
        "# X_Train.shape#get shape of each image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "UaFLC8AxFDoE"
      },
      "outputs": [],
      "source": [
        "# x = X_Train.view(1,3,224,224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "WQvcrnRXFDoE"
      },
      "outputs": [],
      "source": [
        "# x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "ABAggV-CFDoF"
      },
      "outputs": [],
      "source": [
        "# x = F.relu(conv1(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pooling\n",
        "# x = F.max_pool2d(x,2,2)\n",
        "#"
      ],
      "metadata": {
        "id": "Lo3KWQrRH9nn"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x.shape"
      ],
      "metadata": {
        "id": "bmTppXizH9qk"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "erfWvu85FDoF"
      },
      "outputs": [],
      "source": [
        "# x = F.relu(conv2(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x.shape"
      ],
      "metadata": {
        "id": "a08aneLWIzbR"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = F.max_pool2d(x,2,2)\n",
        "# x.shape"
      ],
      "metadata": {
        "id": "7HtbXuXPIzea"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PzqPS96VJKZk"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkUIFczeJKc0"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Odsj4E16JKhZ"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "FEQli5MbFDoF"
      },
      "outputs": [],
      "source": [
        "class_names = ['benign', 'malignant']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "FpZb77mRFDoG"
      },
      "outputs": [],
      "source": [
        "class NeuralBRCA(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3,6,3,1)\n",
        "        self.conv2 = nn.Conv2d(6,16,3,1)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "       #fully connected layer\n",
        "        self.fc1 = nn.Linear(54*54*16,120)\n",
        "        self.fc2 = nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # x = torch.flatten(x,1)\n",
        "        x = x.view(-1,54*54*16)#flatten\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "k_MVcCklFDoG"
      },
      "outputs": [],
      "source": [
        "net = NeuralBRCA()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
        "model = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "beYyoaBBFDoH"
      },
      "outputs": [],
      "source": [
        "def train_one():\n",
        "  for epoch in range(30):\n",
        "      print(f\"Training epoch {epoch}...\")\n",
        "      running_loss = 0.0\n",
        "\n",
        "      for i, data in enumerate(train_loader):\n",
        "          inputs,labels = data\n",
        "          optimizer.zero_grad()\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          loss = loss_function(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "\n",
        "      print(f\"Loss: {running_loss / len(train_loader):.4f}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_two():\n",
        "  # Training loop\n",
        "  num_epochs = 30\n",
        "  for epoch in range(num_epochs):\n",
        "      for phase in ['train', 'test']:\n",
        "          if phase == 'train':\n",
        "              model.train()\n",
        "          else:\n",
        "              model.eval()\n",
        "\n",
        "          running_loss = 0.0\n",
        "          running_corrects = 0\n",
        "\n",
        "          for inputs, labels in dataloaders[phase]:\n",
        "              inputs = inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              with torch.set_grad_enabled(phase == 'train'):\n",
        "                  outputs = model(inputs)\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  loss = loss_function(outputs, labels)\n",
        "\n",
        "                  if phase == 'train':\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "              running_loss += loss.item() * inputs.size(0)\n",
        "              running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "          epoch_loss = running_loss / dataset_sizes[phase]\n",
        "          epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "          print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "  print(\"Training complete!\")"
      ],
      "metadata": {
        "id": "Lsvq2fCMNGr3"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_two()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsKW-YUTNU_3",
        "outputId": "f50f05b8-b1eb-418d-e6a2-499b4df6e248"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.1114 Acc: 0.5000\n",
            "test Loss: 2.0647 Acc: 0.8125\n",
            "train Loss: 2.0802 Acc: 0.6250\n",
            "test Loss: 2.0224 Acc: 0.8125\n",
            "train Loss: 2.0335 Acc: 0.6875\n",
            "test Loss: 1.9715 Acc: 0.8125\n",
            "train Loss: 1.9889 Acc: 0.8750\n",
            "test Loss: 1.9099 Acc: 0.8125\n",
            "train Loss: 1.9334 Acc: 0.7500\n",
            "test Loss: 1.8349 Acc: 0.8125\n",
            "train Loss: 1.8591 Acc: 0.8125\n",
            "test Loss: 1.7423 Acc: 0.8125\n",
            "train Loss: 1.7607 Acc: 0.8750\n",
            "test Loss: 1.6284 Acc: 0.8125\n",
            "train Loss: 1.6564 Acc: 0.7500\n",
            "test Loss: 1.4897 Acc: 0.8125\n",
            "train Loss: 1.5222 Acc: 0.8125\n",
            "test Loss: 1.3259 Acc: 0.8125\n",
            "train Loss: 1.3426 Acc: 0.7500\n",
            "test Loss: 1.1405 Acc: 0.8125\n",
            "train Loss: 1.1692 Acc: 0.8125\n",
            "test Loss: 0.9467 Acc: 0.8125\n",
            "train Loss: 0.9643 Acc: 0.8125\n",
            "test Loss: 0.7658 Acc: 0.8125\n",
            "train Loss: 0.8002 Acc: 0.8125\n",
            "test Loss: 0.6172 Acc: 0.8125\n",
            "train Loss: 0.6354 Acc: 0.8125\n",
            "test Loss: 0.5016 Acc: 0.9375\n",
            "train Loss: 0.5106 Acc: 1.0000\n",
            "test Loss: 0.4157 Acc: 0.9375\n",
            "train Loss: 0.4275 Acc: 1.0000\n",
            "test Loss: 0.3608 Acc: 1.0000\n",
            "train Loss: 0.3502 Acc: 1.0000\n",
            "test Loss: 0.3215 Acc: 1.0000\n",
            "train Loss: 0.3338 Acc: 1.0000\n",
            "test Loss: 0.2722 Acc: 1.0000\n",
            "train Loss: 0.2977 Acc: 1.0000\n",
            "test Loss: 0.2247 Acc: 1.0000\n",
            "train Loss: 0.2091 Acc: 1.0000\n",
            "test Loss: 0.1930 Acc: 1.0000\n",
            "train Loss: 0.2150 Acc: 1.0000\n",
            "test Loss: 0.1615 Acc: 1.0000\n",
            "train Loss: 0.1393 Acc: 1.0000\n",
            "test Loss: 0.1283 Acc: 1.0000\n",
            "train Loss: 0.1247 Acc: 1.0000\n",
            "test Loss: 0.1094 Acc: 1.0000\n",
            "train Loss: 0.1125 Acc: 1.0000\n",
            "test Loss: 0.0871 Acc: 1.0000\n",
            "train Loss: 0.0833 Acc: 1.0000\n",
            "test Loss: 0.0719 Acc: 1.0000\n",
            "train Loss: 0.0604 Acc: 1.0000\n",
            "test Loss: 0.0739 Acc: 1.0000\n",
            "train Loss: 0.0372 Acc: 1.0000\n",
            "test Loss: 0.0749 Acc: 0.9375\n",
            "train Loss: 0.0404 Acc: 1.0000\n",
            "test Loss: 0.0672 Acc: 0.9375\n",
            "train Loss: 0.0289 Acc: 1.0000\n",
            "test Loss: 0.0485 Acc: 1.0000\n",
            "train Loss: 0.0160 Acc: 1.0000\n",
            "test Loss: 0.0343 Acc: 1.0000\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(),'./trained_net.pth')"
      ],
      "metadata": {
        "id": "7lsAFU57Np9v"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = NeuralBRCA()\n",
        "net.load_state_dict(torch.load('./trained_net.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjHdXQQDNqBG",
        "outputId": "e60eeb08-986b-40a2-fa0f-c54de0bfd43e"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-130-aaf33257af9f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load('./trained_net.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "metadata": {
        "id": "Syt5l6J7N9Sk"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = new_transform(image)\n",
        "    image = image.unsqueeze(0)\n",
        "    return image"
      ],
      "metadata": {
        "id": "_UZr-6lWN9V0"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = \"./ml1.jpg\"\n",
        "img2 = \"./mal2.jpg\"\n",
        "img3 = \"./B1.png\"\n",
        "img4 = \"./B2.png\"\n",
        "images = [img1,img2,img3]"
      ],
      "metadata": {
        "id": "a9WXgWcDOcYF"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# net.eval()\n",
        "# with torch.no_grad():\n",
        "#   for image in images:\n",
        "#     output = net(image)\n",
        "#     _,predicted = torch.max(output,1)\n",
        "#     print(f\"Predicted class: {class_names[predicted.item()]}\")"
      ],
      "metadata": {
        "id": "gJcFaZSnN9ZD"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for image_path in images:  # Iterate through image paths\n",
        "    image_tensor = load_image(image_path)  # Load image and transform to Tensor\n",
        "    output = net(image_tensor)  # Pass the Tensor to the model\n",
        "    _,predicted = torch.max(output,1)\n",
        "    print(f\"Predicted class: {class_names[predicted.item()]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3_TAkkhPMLU",
        "outputId": "e190b316-60d5-4b3e-c6c8-b4baf3cd38df"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: malignant\n",
            "Predicted class: benign\n",
            "Predicted class: benign\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}